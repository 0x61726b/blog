---
layout: post
title: "Enabling CEF to Screen Share using getUserMedia() API"
modified: 2015-10-20 00:00:00 -0700
tags: [CEF,getUserMedia,webrtc,c++,chromium,screen share]
image:
  feature: cplusplus.jpg
comments: 
share: 
---

This post/tutorial is intended for being able to teach you how to enable using native screen sharing API of chrome in a CEF
client.This is based on [buglloc](https://github.com/buglloc)'s work. His [patch](https://github.com/buglloc/cef-builds/blob/master/patches/allow_screen_sharing.patch)
is what allowed me to implement screen sharing on my CEF client.

#### Requirements
[Chromium Repository](https://bitbucket.org/chromiumembedded/cef/wiki/Home)

[CEF Screen Sharing Patch](https://github.com/buglloc/cef-builds/blob/master/patches/allow_screen_sharing.patch)

Screen sharing is already possible through getUserMedia but it got removed and moved to chrome extension API for some reason.In a CEF client,
when you call getUserMedia() it will call RequestUserMediaPermission on CefBrowserHost and we will intercept the call and create a MediaStreamDevice 
if the request is a "desktop media" request. On Chrome getUserMedia accepts an encrypted screen or window ID generated by chooseDesktopMedia method on the extension API. Then this code gets decrypted and turned into windows / screen IDs. On CEF, we have to pass a compatible screen or window ID to the MediaStreamDevice and the rest will be handled by WebRTC desktop capture API.
The difference file changes the **cef/libcef/browser/browser_host_impl.cc** file which gets processed when we call getUserMedia.

#### Applying the patch

Go to *chromium\src\cef\patch\patch.cfg* and add 
{% highlight ruby pygments %}

{
 'name': 'allow_screen_sharing',
 'path': '../cef/libcef/browser'
}

{% endhighlight %}

Copy the [patch](https://github.com/buglloc/cef-builds/blob/master/patches/allow_screen_sharing.patch) file to the
**patches** folder. Note that you need to change
{% highlight ruby pygments %}

diff --git a/libcef/browser/browser_host_impl.cc b/libcef/browser/browser_host_impl.cc

{% endhighlight %}

to

{% highlight ruby pygments %}

diff --git browser_host_impl.cc browser_host_impl.cc

{% endhighlight %}

After the patch configuration is done go to **cef\tools** and run patch.bat. You should see the allow_screen_patching applied at the end of the output.
After the patching complete run **translator.bat --root-dir** where root dir is the CEF dir which is **src\cef**.
All done,you need to compile the cefclient.Go to chromium source directory and run 

{% highlight ruby pygments %}

ninja -C out/Debug cefclient

{% endhighlight %}

Compiling should take 3-7 minutes depending on your system.After compiling is complete,CD to tools directory and run 
**make_distrib.bat** This will create a binary distribution which we will use in our CEF client.Note that this will create both *Debug* and *Release* builds for libcef.dll. If you only compiled one version before it might request to recompile in the other configuration,I didnt try so I'm not sure.After the distribution is generated,go to binary_distrib folder,pick your configuration(Debug/Release) then copy the folder into your CEF client.cefsimple isnt required.We should be ready now for the screen sharing allowed libcef.dll.


#### Adding the javascript function for screen/window IDs.

At this point,a simple test is recommended. Create a HTML file and a video node.Call getUserMedia() with desktop media constraint and "screen:0" as ID.
If everything is done correctly,your main monitor video stream should appear properly.


{% highlight ruby pygments %}
 var Constraints = {
        video: {
            mandatory: {
                chromeMediaSource: "desktop",
                chromeMediaSourceId: "screen:0"
            }
        }
    };
    getUserMedia(Constraints, handleUserMedia, handleUserMediaError);
{% endhighlight %}

Without writing any C++ code the above code sample will work if you correctly applied the patch and your primary monitor's video stream will be provided
in the handleUserMedia.

#### Generating Window IDs

As we are making a screen share application,we have to make user pick whatever he/she wants to share. The Chrome extension will prompt a nice dialog with little thumbnails of screens so I will try to make something like this:

<img src="/images/screenPicker.png"/>

Since we can already stream the video,this part is more about how to *generate* the ID so we can provide it to the chromeMediaSourceId.
The steps will be taken here are:

**-Generate window/screen IDs using Win32 API**

**-Create a CefListValue then return a CefV8Array through V8Handler**

**-Implement a custom CEF resource provider to send previews of windows/screens to the UI side.**

**-Iterate through the CefV8Array and create a UI like the picture above.**


## Step 1

I have a class that enumerates windows and screens then returns CefV8 array.Another class for generating previews.I tried to make it as much as 
platform independent but still there needs to be some changes to implement the same on Linux.
{% highlight ruby pygments %}
class ScreenShareUtil
{
public:
	ScreenShareUtil();
	static ScreenShareUtil* Get();
	
	bool EnumScreens(CefListValue* list);
	bool EnumWindows(CefListValue* list);

	bool GetMediaPreview(std::string type, int64 id, std::vector<unsigned char>* outStream);
	
	void CefListValueToV8Array(CefRefPtr<CefListValue> source,CefRefPtr<CefV8Value> target);


protected:
	Win32WindowEnumerator* m_pEnumerator;
};
{% endhighlight %}

This class only calls the **Win32WindowEnumerator** so I'm not including its source.It just returns a CefListValue.
{% highlight ruby pygments %}
class Win32WindowEnumerator : public WindowEnumerationInterface
{
public:
	bool EnumerateWindows(WindowList* list);
	bool EnumerateScreens(ScreenList* list);

	bool GetWindowPreview(int64 id, std::vector<unsigned char>*);
	bool GetScreenPreview(int64 id, std::vector<unsigned char>*);



private:
	//Helper functions
	char* BitmapToByteArray(HBITMAP, int& len);
};
{% endhighlight %}

All methods are virtual on the interface so in the future if I decide to implement the code for linux they will be ready.WindowList and ScreenList are just
structures that hold screenId or windowId and title.To generate a "snapshot" of the window/screen we use Win32 API then convert the bitmap to a char array.

{% highlight ruby pygments %}
//Adaptation of how chromium generates window information
BOOL CALLBACK EnumWindowsProc(HWND hwnd, LPARAM lParam)
{
	Win32WindowEnumerator::WindowEnumerationInterface::WindowList* list =
		reinterpret_cast<Win32WindowEnumerator::WindowEnumerationInterface::WindowList*>(lParam);

	// Skip windows that are invisible, minimized, have no title, or are owned,
	// unless they have the app window style set.
	int len = GetWindowTextLength(hwnd);
	HWND owner = GetWindow(hwnd, GW_OWNER);
	LONG exstyle = GetWindowLong(hwnd, GWL_EXSTYLE);
	if (len == 0 || IsIconic(hwnd) || !IsWindowVisible(hwnd) ||
		(owner && !(exstyle & WS_EX_APPWINDOW))) {
		return TRUE;
	}

	// Skip the Program Manager window and the Start button.
	const size_t kClassLength = 256;
	WCHAR class_name[kClassLength];
	const int class_name_length = GetClassName(hwnd, class_name, kClassLength);

	if (wcscmp(class_name, L"Progman") == 0 || wcscmp(class_name, L"Button") == 0)
		return TRUE;

	if (wcscmp(class_name, L"ApplicationFrameWindow") == 0 ||
		wcscmp(class_name, L"Windows.UI.Core.CoreWindow") == 0) {
		return TRUE;
	}
	OmniWindow window;
	const size_t kTitleLength = 500;
	char window_title[kTitleLength];
	// Truncate the title if it's longer than kTitleLength.
	GetWindowTextA(hwnd, window_title, kTitleLength);
	window.Id = (intptr_t)hwnd;
	window.Hwnd = hwnd;

	window.Title = (window_title);

	if (window.Title.empty())
		return TRUE;


	list->push_back(window);

	return TRUE;
}
//----------------------------------------------------------------------------
bool Win32WindowEnumerator::EnumerateWindows(WindowList* list)
{
	WindowList wl;
	LPARAM param = reinterpret_cast<LPARAM>(&wl);
	if (!EnumWindows(EnumWindowsProc, param))
	{
		return false;
	}
	list->swap(wl);
	return true;
}
//----------------------------------------------------------------------------
{% endhighlight %}

The only important part here is **window.Id = (intptr_t)hwnd;** since **MediaStreamDevice** will want a compatible window ID,which is,on Windows,
**HWND** cast to **intptr_t**.After you generate the ID you can give it to the chromeMediaSourceId and window will be captured properly.

{% highlight ruby pygments %}
//----------------------------------------------------------------------------
bool Win32WindowEnumerator::EnumerateScreens(ScreenList* list)
{
	BOOL enum_result = TRUE;
	for (int device_index = 0;; ++device_index) {
		DISPLAY_DEVICE device;

		device.cb = sizeof(device);
		enum_result = EnumDisplayDevices(NULL, device_index, &device, 0);


		// |enum_result| is 0 if we have enumerated all devices.
		if (!enum_result)
			break;

		// We only care about active displays.
		if (!(device.StateFlags & DISPLAY_DEVICE_ACTIVE))
			continue;

		OmniScreen screen;
		screen.Id = device_index;
		list->push_back(screen);
		LOG(INFO) << screen.Id;
	}
	return true;
}
//----------------------------------------------------------------------------
{% endhighlight %}

Again this is adapted from chromium source. If you have a single monitor there will be only entry which is "0". If you have a secondary monitor
its device index will be "1" and so forth.

After we generate the lists we just pass it as V8 Array.

{% highlight ruby pygments %}
bool ScreenShareUtil::EnumScreens(CefListValue* list)
{
	Win32WindowEnumerator* wi = new Win32WindowEnumerator;
	WindowEnumerationInterface::ScreenList wl;
	wi->EnumerateScreens(&wl);

	WindowEnumerationInterface::ScreenList::iterator It = wl.begin();

	for (It; It != wl.end(); It++)
	{
		std::string id = "screen";
		id.append(":");
		id.append(std::to_string(It->Id));

		CefRefPtr<CefListValue> media = CefListValue::Create();
		media->SetString(0, id);

		if (It->Id == 0)
			media->SetString(1, "Primary Monitor");
		else
			media->SetString(1, "Non-primary Monitor");

		list->SetList(list->GetSize(), media);
	}
	return true;
}
{% endhighlight %}

Windows as well..

{% highlight ruby pygments %}
//----------------------------------------------------------------------------
bool ScreenShareUtil::EnumWindows(CefListValue* list)
{
	Win32WindowEnumerator* wi = new Win32WindowEnumerator;
	WindowEnumerationInterface::WindowList wl;
	wi->EnumerateWindows(&wl);

	WindowEnumerationInterface::WindowList::iterator It = wl.begin();

	for (It; It != wl.end(); It++)
	{
		LOG(INFO) << It->Id << " " << It->Title.c_str();

		std::string id = "window";
		id.append(":");
		id.append(std::to_string(It->Id));

		CefRefPtr<CefListValue> media = CefListValue::Create();
		media->SetString(0, id);
		media->SetString(1, It->Title);
		list->SetList(list->GetSize(), media);
	}


	return true;
}
//----------------------------------------------------------------------------
{% endhighlight %}
The list values will be converted into V8 Arrays on the V8 handler later.

This is it for generating window/screen IDs.Now onto the previews.

## Step 2
This step is up to you since its only about how to return V8 data.

{% highlight ruby pygments %}

virtual bool Execute(const CefString& name,
				CefRefPtr<CefV8Value> object,
				const CefV8ValueList& arguments,
				CefRefPtr<CefV8Value>& retVal,
				CefString& exception)
			{	
			.....
			//Generate screen/window IDs....
			{
						Arken::ScreenShareUtil* ssu = Arken::ScreenShareUtil::Get();
						
						if (arguments.size() != 2)
						{
							retVal = CefV8Value::CreateBool(false);
							LOG(ERROR) << "Invalid call to the eListScreenSharingMedia";
							return false;
						}
						else
						{
							CefRefPtr<CefV8Value> callbackSuccess = arguments[0];
							CefRefPtr<CefV8Value> callbackFailure = arguments[1];

							CefRefPtr<CefListValue> MediaList = CefListValue::Create();

							bool listScreens = true;
							bool listWindows = true;

							if (listScreens)
							{
								ssu->EnumScreens(MediaList);
							}
							if (listWindows)
							{
								ssu->EnumWindows(MediaList);
							}
							CefRefPtr<CefV8Value> v8List = CefV8Value::CreateArray(static_cast<int>(MediaList->GetSize()));
							ssu->CefListValueToV8Array(MediaList, v8List);

							if (static_cast<int>(MediaList->GetSize()) > 0)
							{
								args.push_back(v8List);

								if (callbackSuccess->ExecuteFunctionWithContext(CefV8Context::GetCurrentContext(), object, args))
								{
									LOG(INFO) << it->first + ": ExecuteFunctionWithContext Succeed for Success_Callback";
								}
								else
								{
									HandleException(callbackSuccess, it->first);
								}
							}
							else
							{
								retVal = CefV8Value::CreateBool(false);
								bRet = false;
								errorString = it->first + ": Media List empty!This should not happen!";
								args.push_back(CefV8Value::CreateString(errorString));

								if (callbackFailure->ExecuteFunctionWithContext(CefV8Context::GetCurrentContext(), object, args))
								{
									LOG(INFO) << it->first + ": ExecuteFunctionWithContext Succeed for Failure_Callback";
								}
								else
								{
									HandleException(callbackSuccess, it->first);
								}
							}


							break;
						}
					}

			}

{% endhighlight %}


Here is how the data looks on the console.

<img src="/images/devtools.png"/>


## Step 3

There is lots of Windows code involved.Basically what we do here is take a screenshot,convert to char* array,give it to the CefResourceHandler.
Note that we will implement a custom resource handler called DesktopMediaResourceProvider.on ClientHandler::OnBeforeResourceLoad,
we will parse the URL and look for a custom scheme,it will be like
{% highlight ruby pygments %}
    for (i = 0; i < mediaList.length; i++) {
 		var imgUrl = "http://desktop-media/" + mediaList[i][0].replace(':', '-') + ".bmp";
 		...
 		}
{% endhighlight %}
Then we will set this as image source.ClientHandler::OnBeforeResourceLoad will be called and we will return image data as response.
Here is how to setup a custom resource provider.

{% highlight ruby pygments %}
namespace {
		const char kMimeType[] = "image/x-windows-bmp";
		const char* kErrorContent = "Failed to load resource";
	}
	//----------------------------------------------------------------------------
	DesktopResourceProvider::DesktopResourceProvider(const std::string& Url)
	{
		m_sUrl = Url;
	}
	//----------------------------------------------------------------------------
	bool DesktopResourceProvider::OnRequest(scoped_refptr<CefResourceManager::Request> request)
	{
		CEF_REQUIRE_IO_THREAD();

		LOG(INFO) << "Processing request on DesktopResourceProvider";

		const std::string& url = request->url();

		std::string::size_type delimiter = url.find_last_of('-');
		if (delimiter == std::string::npos)
		{
			return false;
		}
		std::string::size_type start = url.find(m_sUrl) + 1;
		std::string type = url.substr(start + m_sUrl.length(), delimiter - (start + m_sUrl.length()));
		int64 id = atoi(url.substr(delimiter + 1).c_str());

		CefPostTask(TID_UI,
			base::Bind(&DesktopResourceProvider::GetPreviewOnUIThread, type, id, request));
		return true;
	}
	//----------------------------------------------------------------------------
	void DesktopResourceProvider::SendPreviewOnIOThread(std::vector<unsigned char> preview, scoped_refptr<CefResourceManager::Request> request)
	{
		CEF_REQUIRE_IO_THREAD();

		CefRefPtr<CefStreamReader> stream = CefStreamReader::CreateForData(
			static_cast<void*>(preview.data()),
			preview.size()
			);
		//ASSERT(stream.get());

		request->Continue(new CefStreamResourceHandler(
			kMimeType,
			stream
			));
	}
	//----------------------------------------------------------------------------
	void DesktopResourceProvider::SendErrorOnIOThread(scoped_refptr<CefResourceManager::Request> request)
	{
		CEF_REQUIRE_IO_THREAD();

		CefResponse::HeaderMap header_map;
		CefRefPtr<CefStreamReader> stream =
			CefStreamReader::CreateForData(
			static_cast<void*>(const_cast<char*>(kErrorContent)),
			strlen(kErrorContent)
			);

		//ASSERT(stream.get());
		request->Continue(new CefStreamResourceHandler(404, "Not Found", kMimeType, header_map, stream));
	}
	//----------------------------------------------------------------------------
	void DesktopResourceProvider::GetPreviewOnUIThread(const std::string& media_type, int64 media_id, scoped_refptr<CefResourceManager::Request> request)
	{
		CEF_REQUIRE_UI_THREAD();

		LOG(INFO) << "Trying to send preview to the UI thread..";


		std::vector<unsigned char> preview;

		if (ScreenShareUtil::Get()->GetMediaPreview(media_type,media_id,&preview))
		{
			CefPostTask(TID_IO,
				base::Bind(&DesktopResourceProvider::SendPreviewOnIOThread, preview, request));
			preview.clear();
		}
		else
		{
			CefPostTask(TID_IO, base::Bind(&DesktopResourceProvider::SendErrorOnIOThread, request));
		}
	}

{% endhighlight %}

On GetPreviewOnUIThread method, the GetMediaPreview method will return a char* array as mentioned before.

{% highlight ruby pygments %}
bool Win32WindowEnumerator::GetScreenPreview(int64 id, std::vector<unsigned char>* out)
	{
		//Get Screen Rect
		//GetDC(NULL)

		DISPLAY_DEVICE device;
		device.cb = sizeof(device);
		if (!EnumDisplayDevices(NULL, id, &device, 0))
			return false;

		DEVMODE device_mode;
		device_mode.dmSize = sizeof(device_mode);
		device_mode.dmDriverExtra = 0;
		if (!EnumDisplaySettingsEx(
			device.DeviceName, ENUM_CURRENT_SETTINGS, &device_mode, 0))
			return false;

		int x, y, w, h;
		x = device_mode.dmPosition.x;
		y = device_mode.dmPosition.y;
		w = device_mode.dmPelsWidth;
		h = device_mode.dmPelsHeight;


		HDC desktopDC = GetDC(NULL);
		HDC memoryDC = CreateCompatibleDC(desktopDC);
		if (!memoryDC)
			return false;
		HBITMAP hbmScreen;

		hbmScreen = CreateCompatibleBitmap(desktopDC, w, h);
		SelectObject(memoryDC, hbmScreen);

		if (!BitBlt(memoryDC, 0, 0, w, h, desktopDC, x, y, SRCCOPY))
			return false;
		BITMAP bmpScreen;
		GetObject(hbmScreen, sizeof(BITMAP), &bmpScreen);



		int size = 0;
		char* data = BitmapToByteArray(hbmScreen, size);

		*out = std::vector<unsigned char>((unsigned char*)data, (unsigned char*)data + size);

		return true;
	}
{% endhighlight %}

And window Preview..

{% highlight ruby pygments %}
	//----------------------------------------------------------------------------
	bool Win32WindowEnumerator::GetWindowPreview(int64 id, std::vector<unsigned char>* out)
	{
		//Cast back to HWND
		intptr_t i = (intptr_t)id;
		HWND hwnd = (HWND)i;

		HDC hdcWindow;
		HDC hdcScreen = GetDC(NULL);
		HDC hdcMemDC = NULL;

		HBITMAP hbmScreen;


		hdcWindow = GetDC(hwnd);
		if (!hdcWindow)
			return false;

		hdcMemDC = CreateCompatibleDC(hdcWindow);
		if (!hdcMemDC)
			return false;


		//Get screen dimensions
		RECT rcClient;

		if (!GetWindowRect(hwnd, &rcClient))
			return false;


		hbmScreen = CreateCompatibleBitmap(hdcWindow, rcClient.right - rcClient.left, rcClient.bottom - rcClient.top);
		SelectObject(hdcMemDC, hbmScreen);

		if (!BitBlt(hdcMemDC, 0, 0, rcClient.right - rcClient.left, rcClient.bottom - rcClient.top, hdcWindow, 0, 0, SRCCOPY))
			return false;

		BITMAP bmpScreen;
		GetObject(hbmScreen, sizeof(BITMAP), &bmpScreen);

		int size = 0;
		char* data = BitmapToByteArray(hbmScreen, size);
		std::vector<unsigned char> chVector((unsigned char*)data, (unsigned char*)data + size);

		*out = chVector;
		return true;
	}
	//----------------------------------------------------------------------------

{% endhighlight %}

Now everything is set on the C++ side

## Final Step

Now you have previews,window/screen data,only we need to parse the media list coming from V8Handler and use it accordingly.
Here is my poor javascript implementation.

{% highlight ruby pygments %}

for (i = 0; i < mediaList.length; i++) {

        var imgUrl = "http://desktop_app/internals/desktop-media/" + mediaList[i][0].replace(':', '-') + ".bmp";
        var element = container.cloneNode(true);
        element.style.display = "block";
        element.id = "previewItem" + i;
        if (lastElement != undefined) {
            element.getElementsByClassName("previewImage")[0].setAttribute("src", imgUrl);
            element.getElementsByClassName("previewTitle")[0].innerHTML = mediaList[i][1].substr(0, 45) + "...";
            element.getElementsByClassName("chromeId")[0].innerHTML = mediaList[i][0];
            lastElement.appendChild(element);
        } else {

            element.getElementsByClassName("previewImage")[0].setAttribute("src", imgUrl);
            element.getElementsByClassName("previewTitle")[0].innerHTML = mediaList[i][1];
            element.getElementsByClassName("chromeId")[0].innerHTML = mediaList[i][0];
            document.getElementById("previewItem").appendChild(element);

        }

        lastElement = element;

    }

{% endhighlight %}

I tried my best explaining how things work but really you need to figure out some things yourself as the post is already too long.
Here is the final look!

<img src="/images/final.png"/>


Thanks again for [buglloc](https://github.com/buglloc) for his CEF patch.